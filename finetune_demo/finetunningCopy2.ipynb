{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02de4963-1f64-47f9-b4b1-85e441b21a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T08:56:04.761489Z",
     "iopub.status.busy": "2024-03-29T08:56:04.761037Z",
     "iopub.status.idle": "2024-03-29T10:49:33.752546Z",
     "shell.execute_reply": "2024-03-29T10:49:33.751686Z",
     "shell.execute_reply.started": "2024-03-29T08:56:04.761472Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f9a25d5e624af3be7407d20e19e093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n",
      "--> Model\n",
      "\n",
      "--> model has 1.949696M params\n",
      "\n",
      "train_dataset: Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 18228\n",
      "})\n",
      "val_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1292\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7c50fa87454070886c3626193bf8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/1727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/chatglm3-6b-finetunning/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1292\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "***** Running training *****\n",
      "  Num examples = 18,228\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16,000\n",
      "  Number of trainable parameters = 1,949,696\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16000' max='16000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16000/16000 1:42:01, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.119100</td>\n",
       "      <td>No log</td>\n",
       "      <td>41.748266</td>\n",
       "      <td>22.204464</td>\n",
       "      <td>38.631058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.711100</td>\n",
       "      <td>No log</td>\n",
       "      <td>40.269596</td>\n",
       "      <td>20.883608</td>\n",
       "      <td>37.506334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.349500</td>\n",
       "      <td>No log</td>\n",
       "      <td>43.059982</td>\n",
       "      <td>22.622358</td>\n",
       "      <td>39.370498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.326700</td>\n",
       "      <td>No log</td>\n",
       "      <td>42.619660</td>\n",
       "      <td>22.540886</td>\n",
       "      <td>39.391484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.683700</td>\n",
       "      <td>No log</td>\n",
       "      <td>41.255044</td>\n",
       "      <td>20.716206</td>\n",
       "      <td>38.147278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.215700</td>\n",
       "      <td>No log</td>\n",
       "      <td>41.742602</td>\n",
       "      <td>23.533360</td>\n",
       "      <td>38.561410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.035700</td>\n",
       "      <td>No log</td>\n",
       "      <td>43.674496</td>\n",
       "      <td>24.309580</td>\n",
       "      <td>41.427196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.885500</td>\n",
       "      <td>No log</td>\n",
       "      <td>41.574052</td>\n",
       "      <td>21.779292</td>\n",
       "      <td>38.303716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.668500</td>\n",
       "      <td>No log</td>\n",
       "      <td>42.848976</td>\n",
       "      <td>23.791294</td>\n",
       "      <td>39.958062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.444900</td>\n",
       "      <td>No log</td>\n",
       "      <td>42.958842</td>\n",
       "      <td>21.218910</td>\n",
       "      <td>39.650178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>No log</td>\n",
       "      <td>45.138848</td>\n",
       "      <td>25.266672</td>\n",
       "      <td>42.803488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.079000</td>\n",
       "      <td>No log</td>\n",
       "      <td>43.954738</td>\n",
       "      <td>24.308784</td>\n",
       "      <td>40.919650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.748700</td>\n",
       "      <td>No log</td>\n",
       "      <td>45.244554</td>\n",
       "      <td>25.264604</td>\n",
       "      <td>42.014548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.719000</td>\n",
       "      <td>No log</td>\n",
       "      <td>45.734556</td>\n",
       "      <td>25.718704</td>\n",
       "      <td>43.062156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.134800</td>\n",
       "      <td>No log</td>\n",
       "      <td>44.514708</td>\n",
       "      <td>23.855642</td>\n",
       "      <td>41.856746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.257100</td>\n",
       "      <td>No log</td>\n",
       "      <td>45.875316</td>\n",
       "      <td>24.813080</td>\n",
       "      <td>43.258306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.595 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Saving model checkpoint to ./output/checkpoint-1000\n",
      "tokenizer config file saved in ./output/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-1000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-2000\n",
      "tokenizer config file saved in ./output/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-2000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-3000\n",
      "tokenizer config file saved in ./output/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-3000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-4000\n",
      "tokenizer config file saved in ./output/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-4000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-5000\n",
      "tokenizer config file saved in ./output/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-6000\n",
      "tokenizer config file saved in ./output/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-6000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-7000\n",
      "tokenizer config file saved in ./output/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-7000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-8000\n",
      "tokenizer config file saved in ./output/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-8000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-9000\n",
      "tokenizer config file saved in ./output/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-9000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-10000\n",
      "tokenizer config file saved in ./output/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-11000\n",
      "tokenizer config file saved in ./output/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-11000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-12000\n",
      "tokenizer config file saved in ./output/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-12000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-13000\n",
      "tokenizer config file saved in ./output/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-13000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-14000\n",
      "tokenizer config file saved in ./output/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-14000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-15000\n",
      "tokenizer config file saved in ./output/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-15000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-16000\n",
      "tokenizer config file saved in ./output/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-16000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1292\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics: {'rouge-1': 47.783158591331265, 'rouge-2': 29.536678173374614, 'rouge-l': 44.839147755417954}\n"
     ]
    }
   ],
   "source": [
    "%run finetune_hf.py data/ /mnt/workspace/chatglm3-6b configs/lora.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc6c89e6-8e2e-43e9-8810-58ae6d207e1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T10:53:23.680696Z",
     "iopub.status.busy": "2024-03-29T10:53:23.680427Z",
     "iopub.status.idle": "2024-03-29T10:53:32.890232Z",
     "shell.execute_reply": "2024-03-29T10:53:32.889712Z",
     "shell.execute_reply.started": "2024-03-29T10:53:23.680678Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7999c9e776ed4307bd1e0e1c9c0210f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卢比兑美元汇率连续下跌 卢比兑美元汇率跌至149.65:1\n"
     ]
    }
   ],
   "source": [
    "%run inference_hf.py output/checkpoint-16000 --prompt \"经济日报-中国经济网5月23日讯 据中国驻卡拉奇总领事馆经济商务室消息，《论坛快报》报道，巴基斯坦央行的数据显示，卢比兑美元汇率近三个工作日内连续下跌，跌幅达5.84%，合8.26卢比。5月20日（本周一）银行间市场卢比兑美元汇率下降1.20%，已接近149.65:1的历史最低点。\\n此外，公开市场卢比兑美元汇率已达153:1。有消息预测称，基于巴目前经济形势，卢比兑美元汇率还将继续下跌，有可能达到165-170:1。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4221c53-77f9-43c5-8003-eacf01474a4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T11:39:34.244672Z",
     "iopub.status.busy": "2024-03-29T11:39:34.244372Z",
     "iopub.status.idle": "2024-03-29T12:09:59.370518Z",
     "shell.execute_reply": "2024-03-29T12:09:59.369944Z",
     "shell.execute_reply.started": "2024-03-29T11:39:34.244640Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd398e7831f54aa8bf1be287fdffbfb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n",
      "--> Model\n",
      "\n",
      "--> model has 1.949696M params\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/chatglm3-6b-finetunning/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 18228\n",
      "})\n",
      "val_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1292\n",
      "})\n",
      "test_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1292\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Loading model from ./output/checkpoint-16000.\n",
      "***** Running training *****\n",
      "  Num examples = 18,228\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19,000\n",
      "  Number of trainable parameters = 1,949,696\n",
      "  Continuing training from checkpoint, will skip to saved global_step\n",
      "  Continuing training from epoch 0\n",
      "  Continuing training from global step 16000\n",
      "  Will skip the first 0 epochs then the first 16000 batches in the first epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume checkpoint from  checkpoint-16000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19000' max='19000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19000/19000 18:49, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.607200</td>\n",
       "      <td>No log</td>\n",
       "      <td>43.535818</td>\n",
       "      <td>23.790408</td>\n",
       "      <td>40.959628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.674400</td>\n",
       "      <td>No log</td>\n",
       "      <td>42.719464</td>\n",
       "      <td>23.203124</td>\n",
       "      <td>40.208338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.720600</td>\n",
       "      <td>No log</td>\n",
       "      <td>44.927704</td>\n",
       "      <td>24.989120</td>\n",
       "      <td>42.149254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.608 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Saving model checkpoint to ./output/checkpoint-17000\n",
      "tokenizer config file saved in ./output/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-17000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-18000\n",
      "tokenizer config file saved in ./output/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-18000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./output/checkpoint-19000\n",
      "tokenizer config file saved in ./output/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in ./output/checkpoint-19000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1292\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics: {'rouge-1': 47.33048800309597, 'rouge-2': 29.093844272445814, 'rouge-l': 44.39648970588235}\n"
     ]
    }
   ],
   "source": [
    "%run finetune_hf.py data/ /mnt/workspace/chatglm3-6b configs/lora.yaml yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3cf6f0-1d9c-41d6-95dc-f5f7c77a1d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T12:23:47.920465Z",
     "iopub.status.busy": "2024-03-29T12:23:47.920140Z",
     "iopub.status.idle": "2024-03-29T12:23:56.963246Z",
     "shell.execute_reply": "2024-03-29T12:23:56.962775Z",
     "shell.execute_reply.started": "2024-03-29T12:23:47.920447Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d594fb26899b4c2bb05f5c7c31a158bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卢比兑美元汇率连续跌破150:1大关\n"
     ]
    }
   ],
   "source": [
    "%run inference_hf.py output/checkpoint-19000 --prompt \"经济日报-中国经济网5月23日讯 据中国驻卡拉奇总领事馆经济商务室消息，《论坛快报》报道，巴基斯坦央行的数据显示，卢比兑美元汇率近三个工作日内连续下跌，跌幅达5.84%，合8.26卢比。5月20日（本周一）银行间市场卢比兑美元汇率下降1.20%，已接近149.65:1的历史最低点。\\n此外，公开市场卢比兑美元汇率已达153:1。有消息预测称，基于巴目前经济形势，卢比兑美元汇率还将继续下跌，有可能达到165-170:1。\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatglm3-6b-finetunning",
   "language": "python",
   "name": "chatglm3-6b-finetunning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
